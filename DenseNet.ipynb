{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DenseNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wVIx_KIigxPV",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dsO_yGxcg5D8",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 300\n",
        "l = 6\n",
        "num_filter = 35\n",
        "compression = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mB7o3zu1g6eT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73738aad-192e-4e4b-935c-0b47aef018d8"
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vGdqS2iUA1sl",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "            rotation_range=20,\n",
        "            width_shift_range=0.125,\n",
        "            height_shift_range=0.125,\n",
        "            horizontal_flip=True,\n",
        "            fill_mode='nearest',\n",
        "            zoom_range=0.10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3lAk_Mw_5-rn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f0cd48f-584d-4a01-823b-e672ffcfa2a0"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVkpgHsc5-rp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ed6133f-a499-43f1-e217-3aabc28b5dff"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ee-sge5Kg7vr",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 12):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "## transition Blosck\n",
        "def transition(input, num_filter = 12):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "#output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    Out_conv = layers.Conv2D(filters=num_classes,kernel_size = 2,strides = 1, use_bias=False ,padding='valid',\n",
        "              activation='softmax',name='Out_conv')(AvgPooling)\n",
        "\n",
        "    output = layers.Flatten()(Out_conv)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "anPCpQWhhGb7",
        "colab": {}
      },
      "source": [
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "Block_1 = denseblock(First_Conv2D, num_filter)\n",
        "Transition_1 = transition(Block_1, num_filter)\n",
        "\n",
        "Block_2 = denseblock(Transition_1, num_filter)\n",
        "Transition_2 = transition(Block_2, num_filter)\n",
        "\n",
        "Block_3 = denseblock(Transition_2, num_filter)\n",
        "Transition_3 = transition(Block_3, num_filter)\n",
        "\n",
        "Last_Block = denseblock(Transition_3,  num_filter)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1kFh7pdxhNtT",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5209f657-b0c3-46fb-8979-3c9f6c5728de"
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 35)   945         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 35)   140         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 35)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 35)   11025       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 32, 32, 70)   0           conv2d[0][0]                     \n",
            "                                                                 conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 70)   280         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 70)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 35)   22050       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 105)  0           concatenate[0][0]                \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 105)  420         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 105)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 35)   33075       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 140)  0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 140)  560         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 140)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 35)   44100       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 175)  0           concatenate_2[0][0]              \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 175)  700         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 175)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 35)   55125       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 210)  0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 210)  840         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 210)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 35)   66150       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 245)  0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 245)  980         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 245)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 35)   8575        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 35)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 35)   140         average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 35)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 35)   11025       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 16, 16, 70)   0           average_pooling2d[0][0]          \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 70)   280         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 70)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 35)   22050       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 16, 16, 105)  0           concatenate_6[0][0]              \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 105)  420         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 105)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 35)   33075       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 16, 16, 140)  0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 140)  560         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 140)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 35)   44100       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 16, 16, 175)  0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 175)  700         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 175)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 35)   55125       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 16, 16, 210)  0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 210)  840         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 210)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 35)   66150       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 16, 16, 245)  0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 245)  980         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 245)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 35)   8575        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 8, 8, 35)     0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 35)     140         average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 35)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 35)     11025       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 8, 8, 70)     0           average_pooling2d_1[0][0]        \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 70)     280         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 70)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 35)     22050       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 8, 8, 105)    0           concatenate_12[0][0]             \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 105)    420         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 105)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 35)     33075       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 8, 8, 140)    0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 140)    560         concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 140)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 35)     44100       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 8, 8, 175)    0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 175)    700         concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 175)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 35)     55125       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 8, 8, 210)    0           concatenate_15[0][0]             \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 210)    840         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 210)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 35)     66150       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 8, 8, 245)    0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 245)    980         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 245)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 35)     8575        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 4, 4, 35)     0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 4, 4, 35)     140         average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 4, 4, 35)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 4, 4, 35)     11025       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 4, 4, 70)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 4, 4, 70)     280         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 4, 4, 70)     0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 4, 4, 35)     22050       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 4, 4, 105)    0           concatenate_18[0][0]             \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 4, 4, 105)    420         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 4, 4, 105)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 4, 4, 35)     33075       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 4, 4, 140)    0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 4, 4, 140)    560         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 4, 4, 140)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 4, 4, 35)     44100       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 4, 4, 175)    0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 4, 4, 175)    700         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 4, 4, 175)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 4, 4, 35)     55125       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 4, 4, 210)    0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 4, 4, 210)    840         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 4, 4, 210)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 35)     66150       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 4, 4, 245)    0           concatenate_22[0][0]             \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 4, 4, 245)    980         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 4, 4, 245)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 2, 2, 245)    0           activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Out_conv (Conv2D)               (None, 1, 1, 10)     9800        average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 10)           0           Out_conv[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 978,250\n",
            "Trainable params: 970,410\n",
            "Non-trainable params: 7,840\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3mrkic2UA1s5",
        "colab": {}
      },
      "source": [
        "class stop_training_905(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, threshold):\n",
        "        super(stop_training_905, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        val_acc = logs[\"val_accuracy\"]\n",
        "        if val_acc >= self.threshold:\n",
        "            self.model.stop_training = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LQtOzu6Vo_Eg",
        "colab": {}
      },
      "source": [
        "def decay_learn(epoch, lr):\n",
        "    if epoch < 50:\n",
        "        return 0.001\n",
        "    elif epoch >= 50 and epoch < 75:\n",
        "        return 0.0001\n",
        "    else:\n",
        "        return 0.00001\n",
        "\n",
        "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(decay_learn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yilAJwRhA1s8",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"recent_model.hdf5\", monitor='loss', verbose=1,\n",
        "    save_weights_only=False, mode='auto', save_freq='epoch')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OdDHMvfIA1s-",
        "colab": {}
      },
      "source": [
        "training_till_905 = stop_training_905(threshold=0.905)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b4XOsW3ahSkL",
        "colab": {}
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EUKcQN2TA1tD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aec07903-de0d-42a0-cd2d-635b4423f389"
      },
      "source": [
        "datagen.fit(X_train)\n",
        "history_1 = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),epochs=epochs,\n",
        "                       verbose=1, validation_data=(X_test, y_test),\n",
        "                       callbacks=[training_till_905,checkpoint,lr_scheduler])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 1.4719 - accuracy: 0.4652\n",
            "Epoch 00001: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 53s 68ms/step - loss: 1.4719 - accuracy: 0.4652 - val_loss: 2.2943 - val_accuracy: 0.3995 - lr: 0.0010\n",
            "Epoch 2/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 1.0381 - accuracy: 0.6305\n",
            "Epoch 00002: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 52s 66ms/step - loss: 1.0381 - accuracy: 0.6305 - val_loss: 1.0546 - val_accuracy: 0.6484 - lr: 0.0010\n",
            "Epoch 3/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.8604 - accuracy: 0.6969\n",
            "Epoch 00003: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 66ms/step - loss: 0.8604 - accuracy: 0.6969 - val_loss: 1.4157 - val_accuracy: 0.5941 - lr: 0.0010\n",
            "Epoch 4/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.7483 - accuracy: 0.7365\n",
            "Epoch 00004: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.7483 - accuracy: 0.7365 - val_loss: 0.9285 - val_accuracy: 0.6978 - lr: 0.0010\n",
            "Epoch 5/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.6718 - accuracy: 0.7633\n",
            "Epoch 00005: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.6718 - accuracy: 0.7633 - val_loss: 0.8488 - val_accuracy: 0.7411 - lr: 0.0010\n",
            "Epoch 6/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.6168 - accuracy: 0.7854\n",
            "Epoch 00006: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.6168 - accuracy: 0.7854 - val_loss: 0.6646 - val_accuracy: 0.7802 - lr: 0.0010\n",
            "Epoch 7/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.5775 - accuracy: 0.7983\n",
            "Epoch 00007: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.5775 - accuracy: 0.7983 - val_loss: 0.8401 - val_accuracy: 0.7332 - lr: 0.0010\n",
            "Epoch 8/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.5338 - accuracy: 0.8135\n",
            "Epoch 00008: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.5338 - accuracy: 0.8135 - val_loss: 0.5423 - val_accuracy: 0.8159 - lr: 0.0010\n",
            "Epoch 9/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.4990 - accuracy: 0.8278\n",
            "Epoch 00009: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.4990 - accuracy: 0.8278 - val_loss: 0.6217 - val_accuracy: 0.7916 - lr: 0.0010\n",
            "Epoch 10/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.4814 - accuracy: 0.8328\n",
            "Epoch 00010: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.4814 - accuracy: 0.8328 - val_loss: 0.7589 - val_accuracy: 0.7672 - lr: 0.0010\n",
            "Epoch 11/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.8422\n",
            "Epoch 00011: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.4517 - accuracy: 0.8422 - val_loss: 0.6846 - val_accuracy: 0.7852 - lr: 0.0010\n",
            "Epoch 12/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.8516\n",
            "Epoch 00012: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.4304 - accuracy: 0.8516 - val_loss: 0.4721 - val_accuracy: 0.8449 - lr: 0.0010\n",
            "Epoch 13/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.4080 - accuracy: 0.8593\n",
            "Epoch 00013: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.4080 - accuracy: 0.8593 - val_loss: 0.5024 - val_accuracy: 0.8353 - lr: 0.0010\n",
            "Epoch 14/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.8633\n",
            "Epoch 00014: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.3946 - accuracy: 0.8633 - val_loss: 0.4779 - val_accuracy: 0.8426 - lr: 0.0010\n",
            "Epoch 15/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8678\n",
            "Epoch 00015: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.3779 - accuracy: 0.8678 - val_loss: 0.6996 - val_accuracy: 0.7843 - lr: 0.0010\n",
            "Epoch 16/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.8718\n",
            "Epoch 00016: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 63ms/step - loss: 0.3642 - accuracy: 0.8718 - val_loss: 0.6813 - val_accuracy: 0.8001 - lr: 0.0010\n",
            "Epoch 17/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3508 - accuracy: 0.8779\n",
            "Epoch 00017: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.3508 - accuracy: 0.8779 - val_loss: 0.4873 - val_accuracy: 0.8415 - lr: 0.0010\n",
            "Epoch 18/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.8817\n",
            "Epoch 00018: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.3377 - accuracy: 0.8817 - val_loss: 0.5024 - val_accuracy: 0.8377 - lr: 0.0010\n",
            "Epoch 19/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.8861\n",
            "Epoch 00019: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.3239 - accuracy: 0.8861 - val_loss: 0.4824 - val_accuracy: 0.8475 - lr: 0.0010\n",
            "Epoch 20/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3190 - accuracy: 0.8876\n",
            "Epoch 00020: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.3190 - accuracy: 0.8876 - val_loss: 0.3806 - val_accuracy: 0.8789 - lr: 0.0010\n",
            "Epoch 21/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.3040 - accuracy: 0.8938\n",
            "Epoch 00021: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.3040 - accuracy: 0.8938 - val_loss: 0.4583 - val_accuracy: 0.8543 - lr: 0.0010\n",
            "Epoch 22/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2985 - accuracy: 0.8960\n",
            "Epoch 00022: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.2985 - accuracy: 0.8960 - val_loss: 0.4611 - val_accuracy: 0.8525 - lr: 0.0010\n",
            "Epoch 23/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.9009\n",
            "Epoch 00023: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 62ms/step - loss: 0.2833 - accuracy: 0.9009 - val_loss: 0.4736 - val_accuracy: 0.8572 - lr: 0.0010\n",
            "Epoch 24/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.9035\n",
            "Epoch 00024: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 62ms/step - loss: 0.2778 - accuracy: 0.9035 - val_loss: 0.3801 - val_accuracy: 0.8768 - lr: 0.0010\n",
            "Epoch 25/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.9059\n",
            "Epoch 00025: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 62ms/step - loss: 0.2685 - accuracy: 0.9059 - val_loss: 0.5388 - val_accuracy: 0.8474 - lr: 0.0010\n",
            "Epoch 26/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2638 - accuracy: 0.9075\n",
            "Epoch 00026: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 62ms/step - loss: 0.2638 - accuracy: 0.9075 - val_loss: 0.4475 - val_accuracy: 0.8695 - lr: 0.0010\n",
            "Epoch 27/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.9097\n",
            "Epoch 00027: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.2579 - accuracy: 0.9097 - val_loss: 0.3818 - val_accuracy: 0.8743 - lr: 0.0010\n",
            "Epoch 28/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.9128\n",
            "Epoch 00028: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.2513 - accuracy: 0.9128 - val_loss: 0.3862 - val_accuracy: 0.8742 - lr: 0.0010\n",
            "Epoch 29/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.9137\n",
            "Epoch 00029: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.2427 - accuracy: 0.9137 - val_loss: 0.3886 - val_accuracy: 0.8793 - lr: 0.0010\n",
            "Epoch 30/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9193\n",
            "Epoch 00030: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.2333 - accuracy: 0.9193 - val_loss: 0.3831 - val_accuracy: 0.8780 - lr: 0.0010\n",
            "Epoch 31/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.9183\n",
            "Epoch 00031: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.2325 - accuracy: 0.9183 - val_loss: 0.5885 - val_accuracy: 0.8371 - lr: 0.0010\n",
            "Epoch 32/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.9187\n",
            "Epoch 00032: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 62ms/step - loss: 0.2310 - accuracy: 0.9187 - val_loss: 0.3962 - val_accuracy: 0.8755 - lr: 0.0010\n",
            "Epoch 33/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2207 - accuracy: 0.9217\n",
            "Epoch 00033: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 62ms/step - loss: 0.2207 - accuracy: 0.9217 - val_loss: 0.3578 - val_accuracy: 0.8886 - lr: 0.0010\n",
            "Epoch 34/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9242\n",
            "Epoch 00034: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.2151 - accuracy: 0.9242 - val_loss: 0.3892 - val_accuracy: 0.8827 - lr: 0.0010\n",
            "Epoch 35/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.9258\n",
            "Epoch 00035: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 49s 63ms/step - loss: 0.2096 - accuracy: 0.9258 - val_loss: 0.3334 - val_accuracy: 0.8887 - lr: 0.0010\n",
            "Epoch 36/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.9260\n",
            "Epoch 00036: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.2117 - accuracy: 0.9260 - val_loss: 0.3917 - val_accuracy: 0.8808 - lr: 0.0010\n",
            "Epoch 37/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.9286\n",
            "Epoch 00037: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.2006 - accuracy: 0.9286 - val_loss: 0.3939 - val_accuracy: 0.8806 - lr: 0.0010\n",
            "Epoch 38/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.9309\n",
            "Epoch 00038: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.1964 - accuracy: 0.9309 - val_loss: 0.4094 - val_accuracy: 0.8800 - lr: 0.0010\n",
            "Epoch 39/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9326\n",
            "Epoch 00039: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 50s 64ms/step - loss: 0.1919 - accuracy: 0.9326 - val_loss: 0.4086 - val_accuracy: 0.8806 - lr: 0.0010\n",
            "Epoch 40/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9330\n",
            "Epoch 00040: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.1885 - accuracy: 0.9330 - val_loss: 0.4239 - val_accuracy: 0.8790 - lr: 0.0010\n",
            "Epoch 41/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.9329\n",
            "Epoch 00041: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.1872 - accuracy: 0.9329 - val_loss: 0.4621 - val_accuracy: 0.8695 - lr: 0.0010\n",
            "Epoch 42/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 0.9363\n",
            "Epoch 00042: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.1791 - accuracy: 0.9363 - val_loss: 0.3629 - val_accuracy: 0.8933 - lr: 0.0010\n",
            "Epoch 43/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9371\n",
            "Epoch 00043: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.1798 - accuracy: 0.9371 - val_loss: 0.4425 - val_accuracy: 0.8745 - lr: 0.0010\n",
            "Epoch 44/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.9383\n",
            "Epoch 00044: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.1753 - accuracy: 0.9383 - val_loss: 0.4780 - val_accuracy: 0.8680 - lr: 0.0010\n",
            "Epoch 45/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.9396\n",
            "Epoch 00045: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 66ms/step - loss: 0.1686 - accuracy: 0.9396 - val_loss: 0.4600 - val_accuracy: 0.8698 - lr: 0.0010\n",
            "Epoch 46/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.9404\n",
            "Epoch 00046: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 66ms/step - loss: 0.1709 - accuracy: 0.9404 - val_loss: 0.3606 - val_accuracy: 0.8934 - lr: 0.0010\n",
            "Epoch 47/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 0.9402\n",
            "Epoch 00047: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 66ms/step - loss: 0.1672 - accuracy: 0.9402 - val_loss: 0.4091 - val_accuracy: 0.8795 - lr: 0.0010\n",
            "Epoch 48/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1660 - accuracy: 0.9415\n",
            "Epoch 00048: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 66ms/step - loss: 0.1660 - accuracy: 0.9415 - val_loss: 0.3802 - val_accuracy: 0.8876 - lr: 0.0010\n",
            "Epoch 49/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9425\n",
            "Epoch 00049: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 66ms/step - loss: 0.1614 - accuracy: 0.9425 - val_loss: 0.3417 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 50/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.9447\n",
            "Epoch 00050: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 66ms/step - loss: 0.1575 - accuracy: 0.9447 - val_loss: 0.4178 - val_accuracy: 0.8822 - lr: 0.0010\n",
            "Epoch 51/300\n",
            "782/782 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9589\n",
            "Epoch 00051: saving model to recent_model.hdf5\n",
            "782/782 [==============================] - 51s 65ms/step - loss: 0.1173 - accuracy: 0.9589 - val_loss: 0.2997 - val_accuracy: 0.9080 - lr: 1.0000e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rRiZIZbCr1g4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "f35a2edc-d253-446c-a3fe-661b67a43a79"
      },
      "source": [
        "#plotting \n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history_1.history['accuracy'])\n",
        "plt.plot(history_1.history['val_accuracy'])\n",
        "plt.title('Model 2 : accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZcWydmIVhZGr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "96bb1444-777f-4896-b6c3-11e7014ee652"
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.2997 - accuracy: 0.9080\n",
            "Test loss: 0.2997393012046814\n",
            "Test accuracy: 0.9079999923706055\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}